{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 5 — ML Pipeline (Team Notebook)\n",
        "End-to-end ML workflow: preprocessing → modeling → tuning → best accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "import joblib\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(500000, 26) rows, cols\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User ID</th>\n",
              "      <th>User Name</th>\n",
              "      <th>Driver Name</th>\n",
              "      <th>Car Condition</th>\n",
              "      <th>Weather</th>\n",
              "      <th>Traffic Condition</th>\n",
              "      <th>key</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>...</th>\n",
              "      <th>month</th>\n",
              "      <th>weekday</th>\n",
              "      <th>year</th>\n",
              "      <th>jfk_dist</th>\n",
              "      <th>ewr_dist</th>\n",
              "      <th>lga_dist</th>\n",
              "      <th>sol_dist</th>\n",
              "      <th>nyc_dist</th>\n",
              "      <th>distance</th>\n",
              "      <th>bearing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KHVrEVlD</td>\n",
              "      <td>Kimberly Adams</td>\n",
              "      <td>Amy Butler</td>\n",
              "      <td>Very Good</td>\n",
              "      <td>windy</td>\n",
              "      <td>Congested Traffic</td>\n",
              "      <td>2009-06-15 17:26:21.0000001</td>\n",
              "      <td>4.5</td>\n",
              "      <td>2009-06-15 17:26:21</td>\n",
              "      <td>-1.288826</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>20.265840</td>\n",
              "      <td>55.176046</td>\n",
              "      <td>14.342611</td>\n",
              "      <td>34.543548</td>\n",
              "      <td>27.572573</td>\n",
              "      <td>1.030764</td>\n",
              "      <td>-2.918897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lPxIuEri</td>\n",
              "      <td>Justin Tapia</td>\n",
              "      <td>Hannah Zimmerman</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>cloudy</td>\n",
              "      <td>Flow Traffic</td>\n",
              "      <td>2010-01-05 16:52:16.0000002</td>\n",
              "      <td>16.9</td>\n",
              "      <td>2010-01-05 16:52:16</td>\n",
              "      <td>-1.291824</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "      <td>44.667679</td>\n",
              "      <td>31.832358</td>\n",
              "      <td>23.130775</td>\n",
              "      <td>15.125872</td>\n",
              "      <td>8.755732</td>\n",
              "      <td>8.450134</td>\n",
              "      <td>-0.375217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gsVN8JLS</td>\n",
              "      <td>Elizabeth Lopez</td>\n",
              "      <td>Amanda Jackson</td>\n",
              "      <td>Bad</td>\n",
              "      <td>stormy</td>\n",
              "      <td>Congested Traffic</td>\n",
              "      <td>2011-08-18 00:35:00.00000049</td>\n",
              "      <td>5.7</td>\n",
              "      <td>2011-08-18 00:35:00</td>\n",
              "      <td>-1.291242</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>2011</td>\n",
              "      <td>43.597686</td>\n",
              "      <td>33.712082</td>\n",
              "      <td>19.865289</td>\n",
              "      <td>17.722624</td>\n",
              "      <td>9.847344</td>\n",
              "      <td>1.389525</td>\n",
              "      <td>2.599961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9I7kWFgd</td>\n",
              "      <td>Steven Wilson</td>\n",
              "      <td>Amy Horn</td>\n",
              "      <td>Very Good</td>\n",
              "      <td>stormy</td>\n",
              "      <td>Flow Traffic</td>\n",
              "      <td>2012-04-21 04:30:42.0000001</td>\n",
              "      <td>7.7</td>\n",
              "      <td>2012-04-21 04:30:42</td>\n",
              "      <td>-1.291319</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2012</td>\n",
              "      <td>42.642965</td>\n",
              "      <td>32.556289</td>\n",
              "      <td>21.063132</td>\n",
              "      <td>15.738963</td>\n",
              "      <td>7.703421</td>\n",
              "      <td>2.799270</td>\n",
              "      <td>0.133905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8QN5ZaGN</td>\n",
              "      <td>Alexander Andrews</td>\n",
              "      <td>Cassandra Larson</td>\n",
              "      <td>Bad</td>\n",
              "      <td>stormy</td>\n",
              "      <td>Congested Traffic</td>\n",
              "      <td>2010-03-09 07:51:00.000000135</td>\n",
              "      <td>5.3</td>\n",
              "      <td>2010-03-09 07:51:00</td>\n",
              "      <td>-1.290987</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "      <td>43.329953</td>\n",
              "      <td>39.406828</td>\n",
              "      <td>15.219339</td>\n",
              "      <td>23.732406</td>\n",
              "      <td>15.600745</td>\n",
              "      <td>1.999157</td>\n",
              "      <td>-0.502703</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    User ID          User Name       Driver Name Car Condition Weather  \\\n",
              "0  KHVrEVlD     Kimberly Adams        Amy Butler     Very Good   windy   \n",
              "1  lPxIuEri       Justin Tapia  Hannah Zimmerman     Excellent  cloudy   \n",
              "2  gsVN8JLS    Elizabeth Lopez    Amanda Jackson           Bad  stormy   \n",
              "3  9I7kWFgd      Steven Wilson          Amy Horn     Very Good  stormy   \n",
              "4  8QN5ZaGN  Alexander Andrews  Cassandra Larson           Bad  stormy   \n",
              "\n",
              "   Traffic Condition                            key  fare_amount  \\\n",
              "0  Congested Traffic    2009-06-15 17:26:21.0000001          4.5   \n",
              "1       Flow Traffic    2010-01-05 16:52:16.0000002         16.9   \n",
              "2  Congested Traffic   2011-08-18 00:35:00.00000049          5.7   \n",
              "3       Flow Traffic    2012-04-21 04:30:42.0000001          7.7   \n",
              "4  Congested Traffic  2010-03-09 07:51:00.000000135          5.3   \n",
              "\n",
              "       pickup_datetime  pickup_longitude  ...  month  weekday  year  \\\n",
              "0  2009-06-15 17:26:21         -1.288826  ...      6        0  2009   \n",
              "1  2010-01-05 16:52:16         -1.291824  ...      1        1  2010   \n",
              "2  2011-08-18 00:35:00         -1.291242  ...      8        3  2011   \n",
              "3  2012-04-21 04:30:42         -1.291319  ...      4        5  2012   \n",
              "4  2010-03-09 07:51:00         -1.290987  ...      3        1  2010   \n",
              "\n",
              "    jfk_dist   ewr_dist   lga_dist   sol_dist   nyc_dist  distance   bearing  \n",
              "0  20.265840  55.176046  14.342611  34.543548  27.572573  1.030764 -2.918897  \n",
              "1  44.667679  31.832358  23.130775  15.125872   8.755732  8.450134 -0.375217  \n",
              "2  43.597686  33.712082  19.865289  17.722624   9.847344  1.389525  2.599961  \n",
              "3  42.642965  32.556289  21.063132  15.738963   7.703421  2.799270  0.133905  \n",
              "4  43.329953  39.406828  15.219339  23.732406  15.600745  1.999157 -0.502703  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"final_internship_data.csv\")\n",
        "print(df.shape, \"rows, cols\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d9395932",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data after sampling: (10000, 26)\n"
          ]
        }
      ],
      "source": [
        "#for speed training\n",
        "MAX_ROWS = 10000 \n",
        "if len(df) > MAX_ROWS:\n",
        "    df = df.sample(n=MAX_ROWS, random_state=42)\n",
        "print(\"Data after sampling:\", df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TARGET: Traffic Condition\n"
          ]
        }
      ],
      "source": [
        "TARGET=None\n",
        "def infer_target(df: pd.DataFrame):\n",
        "    for c in [\"target\",\"label\",\"class\",\"y\"]:\n",
        "        if c in df.columns: return c\n",
        "    for c in df.columns[::-1]:\n",
        "        if df[c].dtype == 'object' and df[c].nunique(dropna=True) <= 50:\n",
        "            return c\n",
        "    for c in df.columns[::-1]:\n",
        "        if np.issubdtype(df[c].dtype, np.number) and df[c].nunique() <= 10:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "if TARGET is None:\n",
        "    TARGET = infer_target(df)\n",
        "print(\"TARGET:\", TARGET)\n",
        "assert TARGET is not None, \"Please set TARGET column name above.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropped 0 rows with NaN in target.\n"
          ]
        }
      ],
      "source": [
        "# Drop rows where target is NaN (ensures models don't fail on missing labels)\n",
        "before = len(df)\n",
        "df = df.dropna(subset=[TARGET])\n",
        "after = len(df)\n",
        "print(f\"Dropped {before - after} rows with NaN in target.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "58a466e8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropped 0 rows with NaN in target.\n"
          ]
        }
      ],
      "source": [
        "# Drop rows where target is NaN\n",
        "before = len(df)\n",
        "df = df.dropna(subset=[TARGET])\n",
        "after = len(df)\n",
        "print(f\"Dropped {before - after} rows with NaN in target.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "919df865",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000, 25), (2000, 25))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42,\n",
        "    stratify=y if y.nunique() < 50 else None\n",
        ")\n",
        "X_train.shape, X_test.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numeric: 18 | Categorical: 7\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Identify column types on the training data\n",
        "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = X_train.select_dtypes(include=['object','category']).columns.tolist()\n",
        "print(\"Numeric:\", len(num_cols), \"| Categorical:\", len(cat_cols))\n",
        "\n",
        "numeric_tf = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler(with_mean=False))  # keep sparse compatibility\n",
        "])\n",
        "\n",
        "categorical_tf = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse=True))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    (\"num\", numeric_tf, num_cols),\n",
        "    (\"cat\", categorical_tf, cat_cols)\n",
        "], remainder=\"drop\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numeric: 18 | Categorical: 7\n",
            "Preprocessor ready. No NaNs will reach the estimator.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "\n",
        "# Split (recompute here to ensure order is correct in notebook)\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42,\n",
        "    stratify=y if y.nunique() < 50 else None\n",
        ")\n",
        "\n",
        "# Identify columns on training split\n",
        "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = X_train.select_dtypes(include=['object','category']).columns.tolist()\n",
        "print(\"Numeric:\", len(num_cols), \"| Categorical:\", len(cat_cols))\n",
        "\n",
        "# Robust imputers: constant strategy handles even all-NaN columns\n",
        "numeric_tf = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0.0)),\n",
        "    (\"scaler\", StandardScaler(with_mean=False))\n",
        "])\n",
        "\n",
        "categorical_tf = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"__missing__\")),\n",
        "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse=True))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    (\"num\", numeric_tf, num_cols),\n",
        "    (\"cat\", categorical_tf, cat_cols)\n",
        "], remainder=\"drop\")\n",
        "\n",
        "# Sanity check: after fitting the preprocessor, transformed X should have no NaN/Inf\n",
        "Xt = preprocessor.fit_transform(X_train)\n",
        "import scipy\n",
        "if scipy.sparse.issparse(Xt):\n",
        "    # Sparse matrices won't store NaNs; still check data array if CSR/CSC\n",
        "    pass\n",
        "else:\n",
        "    assert np.isfinite(Xt).all(), \"Preprocessor produced non-finite values.\"\n",
        "print(\"Preprocessor ready. No NaNs will reach the estimator.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
        "\n",
        "N_JOBS = -1\n",
        "MODELS = {\n",
        "    \"logreg\": (\n",
        "        LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
        "        {\n",
        "            \"clf__C\": np.logspace(-2, 2, 10),\n",
        "            \"clf__penalty\": [\"l2\"],\n",
        "            \"clf__solver\": [\"saga\"]\n",
        "        }\n",
        "    ),\n",
        "    \"rf\": (\n",
        "        RandomForestClassifier(n_estimators=300, class_weight=\"balanced_subsample\", \n",
        "                               n_jobs=N_JOBS, random_state=42),\n",
        "        {\n",
        "            \"clf__n_estimators\": [200, 300, 500],\n",
        "            \"clf__max_depth\": [None, 10, 20, 40],\n",
        "            \"clf__min_samples_split\": [2, 5, 10]\n",
        "        }\n",
        "    ),\n",
        "    \"gb\": (\n",
        "        GradientBoostingClassifier(random_state=42),\n",
        "        {\n",
        "            \"clf__n_estimators\": [100, 200],\n",
        "            \"clf__learning_rate\": [0.05, 0.1, 0.2],\n",
        "            \"clf__max_depth\": [2, 3]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    ,\n",
        "    \"hgb\": (\n",
        "        HistGradientBoostingClassifier(random_state=42),\n",
        "        {\n",
        "            \"clf__learning_rate\": [0.05, 0.1, 0.2],\n",
        "            \"clf__max_depth\": [None, 6, 12],\n",
        "            \"clf__max_iter\": [100, 200]\n",
        "        }\n",
        "    )\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== logreg ===\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "\n",
            "=== rf ===\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "\n",
            "=== gb ===\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "\n",
            "=== hgb ===\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'accuracy'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_11612\\1125478195.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     34\u001b[39m     search.fit(X_train, y_train)\n\u001b[32m     35\u001b[39m     ...\n\u001b[32m     36\u001b[39m \n\u001b[32m     37\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m pd.DataFrame(results).sort_values(\u001b[33m\"accuracy\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[32mc:\\Users\\Firas\\myenv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7192\u001b[39m             )\n\u001b[32m   7193\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m len(by):\n\u001b[32m   7194\u001b[39m             \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[32m   7195\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m7196\u001b[39m             k = self._get_label_or_level_values(by[\u001b[32m0\u001b[39m], axis=axis)\n\u001b[32m   7197\u001b[39m \n\u001b[32m   7198\u001b[39m             \u001b[38;5;66;03m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[32m   7199\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32mc:\\Users\\Firas\\myenv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
            "\u001b[31mKeyError\u001b[39m: 'accuracy'"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "best_model = None\n",
        "best_acc = -1\n",
        "\n",
        "def to_dense(X):\n",
        "    return X.toarray() if hasattr(X, \"toarray\") else X\n",
        "\n",
        "\n",
        "for name, (estimator, param_grid) in MODELS.items():\n",
        "    print(\"\\n===\", name, \"===\")\n",
        "\n",
        "    if name == \"hgb\":\n",
        "        pipe = Pipeline([\n",
        "            (\"prep\", preprocessor),\n",
        "            (\"densify\", FunctionTransformer(to_dense, accept_sparse=True)),\n",
        "            (\"clf\", estimator)\n",
        "        ])\n",
        "    else:\n",
        "        pipe = Pipeline([\n",
        "            (\"prep\", preprocessor),\n",
        "            (\"clf\", estimator)\n",
        "        ])\n",
        "\n",
        "    search = RandomizedSearchCV(\n",
        "        pipe,\n",
        "        param_distributions=param_grid,\n",
        "        n_iter=10,      \n",
        "        scoring=\"accuracy\",\n",
        "        cv=3,           \n",
        "        random_state=42,\n",
        "        n_jobs=N_JOBS,\n",
        "        verbose=1\n",
        "    )\n",
        "    search.fit(X_train, y_train)\n",
        "    ...\n",
        "\n",
        "\n",
        "pd.DataFrame(results).sort_values(\"accuracy\", ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'predict'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m y_pred = \u001b[43mbest_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m(X_test)\n\u001b[32m      2\u001b[39m acc = accuracy_score(y_test, y_pred)\n\u001b[32m      3\u001b[39m f1 = f1_score(y_test, y_pred, average=\u001b[33m\"\u001b[39m\u001b[33mmacro\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'predict'"
          ]
        }
      ],
      "source": [
        "y_pred = best_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
        "print(f\"\\nBEST MODEL ACCURACY: {acc:.4f} | Macro-F1: {f1:.4f}\")\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.imshow(cm, cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted'); plt.ylabel('True')\n",
        "for (i,j), v in np.ndenumerate(cm):\n",
        "    plt.text(j, i, str(v), ha='center', va='center')\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(best_model, f\"best_model_{TEAM_NAME}.joblib\")\n",
        "print(\"Saved:\", f\"best_model_{TEAM_NAME}.joblib\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ab84498f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Winner picked from your printed results:\n",
        "rf_best_params = {\n",
        "    \"n_estimators\": 500,\n",
        "    \"min_samples_split\": 10,\n",
        "    \"max_depth\": None,\n",
        "    \"class_weight\": \"balanced_subsample\",\n",
        "    \"n_jobs\": -1,\n",
        "    \"random_state\": 42,\n",
        "}\n",
        "best_model = Pipeline([\n",
        "    (\"prep\", preprocessor),\n",
        "    (\"clf\", RandomForestClassifier(**rf_best_params))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4e1bf38d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FINAL (RandomForest)  Accuracy: 0.3450 | Macro-F1: 0.3385\n",
            "\n",
            "Classification report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "Congested Traffic       0.34      0.36      0.35       670\n",
            "    Dense Traffic       0.37      0.44      0.40       675\n",
            "     Flow Traffic       0.32      0.23      0.26       655\n",
            "\n",
            "         accuracy                           0.34      2000\n",
            "        macro avg       0.34      0.34      0.34      2000\n",
            "     weighted avg       0.34      0.34      0.34      2000\n",
            "\n",
            "Saved: best_model_task5_model.joblib\n"
          ]
        }
      ],
      "source": [
        "# Fit once on your 10k sample split\n",
        "TEAM_NAME='task5_model'\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "y_pred = best_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1  = f1_score(y_test, y_pred, average=\"macro\")\n",
        "print(f\"FINAL (RandomForest)  Accuracy: {acc:.4f} | Macro-F1: {f1:.4f}\")\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Save for Django deployment\n",
        "import joblib\n",
        "joblib.dump(best_model, f\"best_model_{TEAM_NAME}.joblib\")\n",
        "print(\"Saved:\", f\"best_model_{TEAM_NAME}.joblib\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58847e81",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (myenv)",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
