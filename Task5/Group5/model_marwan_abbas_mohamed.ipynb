{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71d59088",
   "metadata": {},
   "source": [
    "# import importan functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cffe502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "#model imports\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "#evaluation\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baecd4f8",
   "metadata": {},
   "source": [
    "## Read dataSet from CSV to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c1a69c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"D:\\AI_road_map\\python\\dataSets\\final_internship_data.csv\"\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1e2c7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   User ID            500000 non-null  object \n",
      " 1   User Name          500000 non-null  object \n",
      " 2   Driver Name        500000 non-null  object \n",
      " 3   Car Condition      500000 non-null  object \n",
      " 4   Weather            500000 non-null  object \n",
      " 5   Traffic Condition  500000 non-null  object \n",
      " 6   key                500000 non-null  object \n",
      " 7   fare_amount        500000 non-null  float64\n",
      " 8   pickup_datetime    500000 non-null  object \n",
      " 9   pickup_longitude   500000 non-null  float64\n",
      " 10  pickup_latitude    500000 non-null  float64\n",
      " 11  dropoff_longitude  499995 non-null  float64\n",
      " 12  dropoff_latitude   499995 non-null  float64\n",
      " 13  passenger_count    500000 non-null  int64  \n",
      " 14  hour               500000 non-null  int64  \n",
      " 15  day                500000 non-null  int64  \n",
      " 16  month              500000 non-null  int64  \n",
      " 17  weekday            500000 non-null  int64  \n",
      " 18  year               500000 non-null  int64  \n",
      " 19  jfk_dist           499995 non-null  float64\n",
      " 20  ewr_dist           499995 non-null  float64\n",
      " 21  lga_dist           499995 non-null  float64\n",
      " 22  sol_dist           499995 non-null  float64\n",
      " 23  nyc_dist           499995 non-null  float64\n",
      " 24  distance           499995 non-null  float64\n",
      " 25  bearing            499995 non-null  float64\n",
      "dtypes: float64(12), int64(6), object(8)\n",
      "memory usage: 99.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bf0311",
   "metadata": {},
   "source": [
    "## Excluded features that weren’t useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5371f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels=['User ID', 'User Name', 'Driver Name', 'key', 'pickup_datetime','Weather','Traffic Condition','Car Condition'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9e9450",
   "metadata": {},
   "source": [
    "## Removed null values since they were few in number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "195da33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4d89f5",
   "metadata": {},
   "source": [
    "## Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab30b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_zscore(data, column, threshold=3):\n",
    "\n",
    "    z_scores = zscore(data[column])\n",
    "    mask = abs(z_scores) < threshold\n",
    "    return data[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e39c58e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feauters = ['fare_amount', 'pickup_longitude', 'pickup_latitude',\n",
    "            'dropoff_longitude', 'dropoff_latitude', 'jfk_dist', 'ewr_dist',\n",
    "            'lga_dist','sol_dist', 'nyc_dist', 'distance',]\n",
    "\n",
    "for col in feauters:\n",
    "    data = remove_outliers_zscore(data, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b1b98",
   "metadata": {},
   "source": [
    "## Split the dataset into features and target, then divided into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54594f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(labels=[\"fare_amount\"],axis=1)\n",
    "Y = data[\"fare_amount\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2724cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2 , random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cabe99",
   "metadata": {},
   "source": [
    "## Feature extaraction and scalining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9264d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_featuers = ['pickup_longitude', 'pickup_latitude',\n",
    "            'dropoff_longitude', 'dropoff_latitude', 'jfk_dist', 'ewr_dist',\n",
    "            'lga_dist','sol_dist', 'nyc_dist']\n",
    "pca_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(random_state=42,n_components=0.95))\n",
    "])\n",
    "\n",
    "# Define column transformer\n",
    "pca_colum_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('pca_features', pca_pipeline, PCA_featuers),\n",
    "        ('scale_rest', StandardScaler(), [col for col in x_train.columns if col not in PCA_featuers])\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# Transform\n",
    "x_train_scaled = pca_colum_transformer.fit_transform(x_train)\n",
    "x_test_scaled = pca_colum_transformer.transform(x_test)\n",
    "# To DataFrame\n",
    "x_train_scaled = pd.DataFrame(\n",
    "    x_train_scaled,\n",
    "    columns=pca_colum_transformer.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1a10e8",
   "metadata": {},
   "source": [
    "## Check for multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55d75f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Feature   VIF\n",
      "0              pca0  1.01\n",
      "1              pca1  1.12\n",
      "2              pca2  1.55\n",
      "3   passenger_count  1.00\n",
      "4              hour  1.01\n",
      "5               day  1.00\n",
      "6             month  1.01\n",
      "7           weekday  1.01\n",
      "8              year  1.01\n",
      "9          distance  1.11\n",
      "10          bearing  1.57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def compute_vif(X_df):\n",
    "    vif_dict = {}\n",
    "    for col in X_df.columns:\n",
    "        X_other = X_df.drop(columns=[col])\n",
    "        y_target = X_df[col]\n",
    "        model = LinearRegression().fit(X_other, y_target)\n",
    "        r2 = model.score(X_other, y_target)\n",
    "        tolerance = 1 - r2\n",
    "        vif = 1 / tolerance if tolerance != 0 else float('inf')\n",
    "        vif_dict[col] = round(vif, 2)\n",
    "    return pd.DataFrame({'Feature': vif_dict.keys(), 'VIF': vif_dict.values()})\n",
    "    \n",
    "vif_df = compute_vif(x_train_scaled)\n",
    "print(vif_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b69a5",
   "metadata": {},
   "source": [
    "## features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "683f5f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = RandomForestRegressor()\n",
    "importance.fit(x_train_scaled,y_train)\n",
    "\n",
    "important = importance.feature_importances_\n",
    "feauters = x_train_scaled.columns\n",
    "\n",
    "pd.DataFrame({\n",
    "        'featuers' : feauters,\n",
    "        'importance' : important\n",
    "}).sort_values(by=\"importance\",ascending=False,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9d9cb013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>featuers</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>distance</td>\n",
       "      <td>0.733279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca0</td>\n",
       "      <td>0.051372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pca1</td>\n",
       "      <td>0.040228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>year</td>\n",
       "      <td>0.039447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bearing</td>\n",
       "      <td>0.034248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pca2</td>\n",
       "      <td>0.023259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hour</td>\n",
       "      <td>0.021657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>day</td>\n",
       "      <td>0.013510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>month</td>\n",
       "      <td>0.012565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>weekday</td>\n",
       "      <td>0.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Car Condition</td>\n",
       "      <td>0.004833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>passenger_count</td>\n",
       "      <td>0.004675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Weather_stormy</td>\n",
       "      <td>0.001897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Traffic Condition_Congested Traffic</td>\n",
       "      <td>0.001887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Traffic Condition_Dense Traffic</td>\n",
       "      <td>0.001883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weather_cloudy</td>\n",
       "      <td>0.001822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Weather_sunny</td>\n",
       "      <td>0.001785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weather_rainy</td>\n",
       "      <td>0.001765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               featuers  importance\n",
       "16                             distance    0.733279\n",
       "0                                  pca0    0.051372\n",
       "1                                  pca1    0.040228\n",
       "15                                 year    0.039447\n",
       "17                              bearing    0.034248\n",
       "2                                  pca2    0.023259\n",
       "11                                 hour    0.021657\n",
       "12                                  day    0.013510\n",
       "13                                month    0.012565\n",
       "14                              weekday    0.009888\n",
       "9                         Car Condition    0.004833\n",
       "10                      passenger_count    0.004675\n",
       "5                        Weather_stormy    0.001897\n",
       "7   Traffic Condition_Congested Traffic    0.001887\n",
       "8       Traffic Condition_Dense Traffic    0.001883\n",
       "3                        Weather_cloudy    0.001822\n",
       "6                         Weather_sunny    0.001785\n",
       "4                         Weather_rainy    0.001765"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "        'featuers' : feauters,\n",
    "        'importance' : important\n",
    "})\n",
    "\n",
    "df.sort_values(by=\"importance\",ascending=False,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "20e8fbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance           0.785844\n",
      "pca2               0.479855\n",
      "year               0.462017\n",
      "pca1               0.090528\n",
      "bearing            0.058874\n",
      "pca0               0.054168\n",
      "hour               0.014831\n",
      "month              0.012855\n",
      "passenger_count    0.008392\n",
      "weekday            0.002283\n",
      "day                0.001853\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "mi = mutual_info_regression(x_train_scaled, y_train)\n",
    "mi_series = pd.Series(mi, index=x_train_scaled.columns).sort_values(ascending=False)\n",
    "print(mi_series)  # Top 10 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb82cf",
   "metadata": {},
   "source": [
    "## Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e7860aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eslamia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=4,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(x_train_scaled,y_train)\n",
    "\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "y_pred_train = model.predict(x_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f538dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set:\n",
      "MAE: 1.364682667703858\n",
      "RMSE: 2.2846530280952537\n",
      "R²: 0.8219737503509096\n",
      "\n",
      "Train Set:\n",
      "MAE: 0.9201935920317754\n",
      "RMSE: 1.5726088798368119\n",
      "R²: 0.914680667937954\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Test Set:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R²:\", r2_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nTrain Set:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_train, y_pred_train))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "print(\"R²:\", r2_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e54d8a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = XGBRegressor( )\n",
    "model2.fit(x_train_scaled,y_train)\n",
    "\n",
    "y_pred2 = model2.predict(x_test_scaled)\n",
    "y_pred_train2 = model2.predict(x_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e91057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set:\n",
      "MAE: 1.3183865309043195\n",
      "RMSE: 2.241493292549924\n",
      "R²: 0.8286364602178582\n",
      "\n",
      "Train Set:\n",
      "MAE: 1.2528237208896473\n",
      "RMSE: 2.0503375468662712\n",
      "R²: 0.8549703732666851\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Test Set:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred2))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred2)))\n",
    "print(\"R²:\", r2_score(y_test, y_pred2))\n",
    "\n",
    "print(\"\\nTrain Set:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_train, y_pred_train2))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_train, y_pred_train2)))\n",
    "print(\"R²:\", r2_score(y_train, y_pred_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "26c1ca66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eslamia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model3 = LinearRegression()\n",
    "model3.fit(x_train_scaled,y_train)\n",
    "\n",
    "y_pred3 = model3.predict(x_test_scaled)\n",
    "y_pred_train3 = model3.predict(x_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "83089c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set:\n",
      "MAE: 1.8131996212865702\n",
      "RMSE: 2.8079922582701884\n",
      "R²: 0.7310724164261337\n",
      "\n",
      "Train Set:\n",
      "MAE: 1.7887366282621222\n",
      "RMSE: 2.740245241342703\n",
      "R²: 0.7409492439747407\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Set:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred3))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred3)))\n",
    "print(\"R²:\", r2_score(y_test, y_pred3))\n",
    "\n",
    "print(\"\\nTrain Set:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_train, y_pred_train3))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_train, y_pred_train3)))\n",
    "print(\"R²:\", r2_score(y_train, y_pred_train3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "816a5d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eslamia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model4 = KNeighborsRegressor()\n",
    "model4.fit(x_train_scaled,y_train)\n",
    "\n",
    "y_pred4 = model4.predict(x_test_scaled)\n",
    "y_pred_train4 = model4.predict(x_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "72bc12e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set:\n",
      "MAE: 1.7528385575620018\n",
      "RMSE: 2.6910778615036537\n",
      "R²: 0.7530005055706375\n",
      "\n",
      "Train Set:\n",
      "MAE: 1.4170319572067602\n",
      "RMSE: 2.135453495195475\n",
      "R²: 0.842679167589044\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Set:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred4))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred4)))\n",
    "print(\"R²:\", r2_score(y_test, y_pred4))\n",
    "\n",
    "print(\"\\nTrain Set:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_train, y_pred_train4))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_train, y_pred_train4)))\n",
    "print(\"R²:\", r2_score(y_train, y_pred_train4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff22352a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eslamia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model5 = DecisionTreeRegressor(random_state=42,)\n",
    "model5.fit(x_train_scaled,y_train)\n",
    "\n",
    "y_pred5 = model5.predict(x_test_scaled)\n",
    "y_pred_train5 = model5.predict(x_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22d0d846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set:\n",
      "MAE: 1.9948588081046241\n",
      "RMSE: 3.322270885889596\n",
      "R²: 0.6235445246791123\n",
      "\n",
      "Train Set:\n",
      "MAE: 1.1017826843985587e-06\n",
      "RMSE: 0.0004694214917072565\n",
      "R²: 0.9999999923979287\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Set:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred5))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred5)))\n",
    "print(\"R²:\", r2_score(y_test, y_pred5))\n",
    "\n",
    "print(\"\\nTrain Set:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_train, y_pred_train5))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_train, y_pred_train5)))\n",
    "print(\"R²:\", r2_score(y_train, y_pred_train5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267204b",
   "metadata": {},
   "source": [
    "## hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e4514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb_model = XGBRegressor(learning_rate = 0.1,n_estimators=300)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [6, 10, 15],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 1],\n",
    "    'reg_alpha': [0, 0.1, 1.0],\n",
    "    'reg_lambda': [1.0, 1.5, 2.0],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(x_train_scaled, y_train)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d659ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "xgb_model = XGBRegressor(n_estimators=300)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate' : [0.01,.03,0.1],\n",
    "    'max_depth': [6, 10, 15],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0.1, 0.3, 1],\n",
    "    'reg_alpha': [0, 0.1, 1.0],\n",
    "    'reg_lambda': [1.0, 2.5, 5.0],\n",
    "}\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,  \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=3, \n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search.fit(x_train_scaled, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
